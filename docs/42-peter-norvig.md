# 42 Peter Norvig


![Peter Norvig](https://encrypted-tbn0.gstatic.com/licensed-image?q=tbn:ANd9GcTDBLF9ZdHfL6WEARbUXnGpI9IzTeKBPpYPf3kLgPQPNBkcWggciNyWXbl0B6DfHnYF-tEy&s=19)

American computer scientist

> Peter Norvig is an American computer scientist and Distinguished Education Fellow at the Stanford Institute for Human-Centered AI. He previously served as a director of research and search quality at Google.

Website: https://www.norvig.com/

Source: [Wikipedia](https://en.wikipedia.org/wiki/Peter_Norvig)

- **Born**: 1956 , United States
- **Education**: University of California, Berkeley (1980–1986), Brown University (1974–1978), and UC Berkeley College of Engineering
- **Awards**: AAAI Fellow (2001) and ACM Fellow (2006)
- **Affiliation**: Google Inc.
- **Research interests**: Artificial Intelligence
- **Doctoral advisor**: Robert Wilensky


## The Main Arguments

- **Advancements in AI and Hardware**: Norvig discusses the transformative impact of hardware advancements, particularly GPUs and TPUs, on AI capabilities. This evolution has enabled the development of more complex algorithms and the processing of larger datasets, which are essential for modern AI applications. The significance lies in how these technological improvements have shifted the landscape of AI research and application.

- **Utility Functions and Ethical Frameworks**: The conversation emphasizes the need to define what utility functions should represent in AI systems. Norvig argues that the challenge is not just about optimizing these functions but understanding the underlying human values and ethics they should reflect. This perspective highlights the philosophical dimensions of AI development and the importance of aligning AI goals with societal values.

- **Fairness and Bias in AI**: Norvig addresses the complexities of ensuring fairness in AI, especially in sensitive areas like criminal justice. He points out that achieving fairness across diverse demographic groups often involves difficult trade-offs, which require human deliberation. This argument underscores the ethical dilemmas faced in AI deployment and the need for careful consideration of societal impacts.

- **Education and Accessibility in AI**: The discussion touches on the role of education, particularly through MOOCs, in democratizing access to AI knowledge. Norvig reflects on his experiences teaching AI and stresses the importance of motivation and community in online learning environments. This point highlights the need for accessible education to foster a broader understanding of AI.

- **Future of AI and Human-Level Intelligence**: Norvig expresses skepticism about the pursuit of human-level AI, advocating instead for the development of useful tools that enhance human capabilities. He suggests that AI should aim to exceed human performance in specific tasks rather than replicate human intelligence. This perspective encourages a pragmatic approach to AI development, focusing on practical applications rather than theoretical aspirations.

## Any Notable Quotes

- "The hard part is deciding what is my utility function. What do I want?"
  - This quote encapsulates the philosophical shift in AI research towards understanding human values and ethics, emphasizing the complexity of defining goals for AI systems.

- "We want to have a marketplace for attention, but we need to change the playing field so we feel more like these things are on my side."
  - Norvig highlights the ethical implications of technology designed to capture human attention, advocating for systems that prioritize long-term well-being over short-term engagement.

- "We need to have a conversation rather than just an explanation."
  - This statement emphasizes the importance of dialogue in understanding AI decisions, advocating for deeper engagement with technology beyond surface-level explanations.

- "The most amazing thing about humans is that you can walk into a coffee shop and not kill each other."
  - A humorous yet profound observation about human trust and social interaction, contrasting with the skepticism often directed at AI.

- "We should be aiming far beyond human level for many things."
  - Norvig challenges the notion that AI should strive to replicate human intelligence, suggesting a focus on enhancing capabilities instead.

## Relevant Topics or Themes

- **AI Ethics and Philosophy**: The episode delves into the ethical implications of AI, particularly in defining utility functions and ensuring fairness. Norvig discusses the challenges of encoding human values into AI systems, highlighting the philosophical dimensions of AI research.

- **Technological Advancements**: The conversation covers the rapid evolution of hardware and its impact on AI capabilities. Norvig notes how increased computational power has enabled more sophisticated algorithms and applications, illustrating the interplay between technology and AI development.

- **Education and Accessibility**: Norvig reflects on the role of education in AI, particularly through MOOCs. He emphasizes the importance of motivation and community in online learning, suggesting that these factors are crucial for success and broader understanding of AI.

- **Human-AI Interaction**: The discussion touches on the nature of human relationships with AI systems, exploring the potential for emotional connections. Norvig suggests that humans have a natural tendency to anthropomorphize technology, which raises questions about trust and reliance on AI.

- **Future Directions in AI**: Norvig speculates on the future of AI, advocating for a focus on practical applications rather than the pursuit of human-level intelligence. He emphasizes the need for AI to be a useful tool that enhances human capabilities, reflecting a pragmatic approach to AI development.

Overall, the episode provides a comprehensive exploration of the current state and future directions of AI, framed by ethical considerations and the importance of education. Norvig's insights reflect a deep understanding of both the technical and philosophical challenges facing the field, while also addressing societal implications and the need for responsible AI development.