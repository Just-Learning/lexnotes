# 71 Vladimir Vapnik


![Vladimir Vapnik](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRfaaM3ay01KsDGyn3xgwu4dQorbyDuk5RDk7grFw&s=0)

Computer scientist

> Vladimir Naumovich Vapnik is a computer scientist, researcher, and academic. He is one of the main developers of the Vapnikâ€“Chervonenkis theory of statistical learning and the co-inventor of the support-vector machine method and support-vector...

Source: [Wikipedia](https://en.wikipedia.org/wiki/Vladimir_Vapnik)

- **Place of birth**: Soviet Union
- **Affiliation**: NEC Laboratories
- **Research interests**: Machine Learning, Statistics, and Computer Science


## The Main Arguments

- **Distinction Between Engineering and Understanding Intelligence**: Vapnik emphasizes that engineering intelligence, which focuses on creating systems that mimic human behavior, is fundamentally different from understanding intelligence, which seeks to grasp the underlying principles of intelligence. This distinction is crucial as it highlights the limitations of current AI systems, which may perform tasks well but lack true comprehension.

- **Role of Predicates in Human Behavior**: Vapnik introduces the concept of predicates as fundamental units that can explain human behavior. He draws on Vladimir Propp's work on folk tales to suggest that similar predicates could be used to analyze various human activities, including storytelling and AI behavior. This idea underscores the importance of identifying effective predicates for understanding both human cognition and machine learning.

- **Challenges in Learning from Limited Data**: Vapnik argues that achieving high performance in tasks like digit recognition with minimal training data necessitates intelligence. He stresses the need for good predicates that can generalize well from limited examples, which poses a significant challenge in current machine learning paradigms. This point raises questions about the efficiency and effectiveness of existing AI training methods.

- **Weak and Strong Convergence**: The discussion includes the concepts of weak and strong convergence in function approximation. Vapnik explains that weak convergence focuses on integral properties of functions, which are essential for understanding how well a model generalizes from training data. This distinction is significant for developing more robust learning algorithms.

- **Discovery of Good Predicates**: Vapnik posits that the essence of intelligence lies in the discovery of good predicates. He believes that while machines can assist in this process, the nuanced understanding required to identify effective predicates may still be a uniquely human endeavor. This perspective invites further exploration into the interplay between human cognition and machine learning.

## Any Notable Quotes

- "Engineering is imitation of human activity. You have to make a device which behaves as a human behaves."
  - This quote encapsulates Vapnik's view on the limitations of AI, emphasizing that mere imitation does not equate to understanding.

- "I believe that intelligence is a world of ideas, but it is a world of pure ideas."
  - This statement reflects Vapnik's philosophical stance on intelligence, suggesting that true understanding transcends practical applications.

- "To build records using say, 100, 200 times less examples, you need intelligence."
  - Here, Vapnik underscores the challenge of learning efficiently, which is a critical issue in AI research.

- "If you will use all possible functions from Hilbert space, all possible predicates, you don't need training data."
  - This quote highlights the theoretical underpinnings of Vapnik's arguments regarding function approximation and the potential for generalization in machine learning.

- "The essence of intelligence is the discovery of good predicates."
  - This succinctly summarizes Vapnik's core argument about the nature of intelligence and its relationship to learning.

## Relevant Topics or Themes

- **Philosophy of Intelligence**: The episode delves into philosophical discussions about the nature of intelligence, referencing Plato and the theory of forms. Vapnik's perspective suggests that understanding intelligence requires a deep exploration of abstract ideas, which can inform AI development.

- **Machine Learning and AI**: The conversation frequently touches on machine learning concepts, particularly the challenges of generalization and the importance of predicates in learning from data. Vapnik critiques current deep learning approaches, advocating for a more principled understanding of function approximation.

- **Cognitive Science and Human Behavior**: Vapnik draws parallels between human cognitive processes and AI, suggesting that understanding human behavior through predicates can inform AI development. This theme connects to broader discussions in cognitive science about how humans process information.

- **Statistical Learning Theory**: The episode discusses Vapnik's contributions to statistical learning theory, including concepts like VC dimension and convergence. These ideas are foundational in understanding the capacity of learning algorithms and their performance.

- **Interdisciplinary Connections**: The dialogue highlights the intersections between literature, philosophy, and AI, particularly through the lens of Propp's work on narratives. Vapnik's insights suggest that understanding stories and human behavior can inform AI research and development.

Overall, the episode presents a rich tapestry of ideas that bridge technical discussions in AI with philosophical inquiries into the nature of intelligence and understanding. The conversation also touches on the importance of patience and persistence in research, as Vapnik reflects on his long journey in the field of machine learning.