# 208 Jeff Hawkins 2


![Jeff Hawkins](https://encrypted-tbn0.gstatic.com/licensed-image?q=tbn:ANd9GcTOy26amueRq0Tw8CRuvpP5plZoE4OkMNHofeQlj7X8nvquuHoYTnOgDYLW5JDt4GrLXwkE&s=19)

American businessman and neuroscientist

> Jeffrey Hawkins is an American businessman, neuroscientist and engineer. He co-founded Palm Computing — where he co-created the PalmPilot and Treo — and Handspring. He subsequently turned to work on neuroscience, founding the Redwood Center for...

Source: [Wikipedia](https://en.wikipedia.org/wiki/Jeff_Hawkins)

- **Born**: 1957 , New York, NY
- **Education**: Cornell University, University of California, Berkeley, and Harborfields High School


## The Main Arguments

- **Neocortex as a Distributed Modeling System**: Hawkins argues that the neocortex functions as a collection of independent modeling systems, each creating its own representation of the world. This challenges the traditional view of intelligence as centralized, suggesting a more complex and distributed understanding of cognitive processes. This perspective is significant as it reframes our approach to both neuroscience and artificial intelligence (AI).

- **The Thousand Brains Theory**: Hawkins introduces the concept that each cortical column in the neocortex acts as a "mini-brain," contributing to our overall intelligence through a voting mechanism. This idea emphasizes that knowledge is not localized but distributed, which is crucial for understanding learning and memory.

- **Hierarchical Representation of Knowledge**: Hawkins explains how the brain learns the hierarchical structure of the world, from simple objects to complex concepts. This hierarchical modeling allows for sophisticated interactions with the environment, indicating that cognitive processes are deeply rooted in physical experiences.

- **Prediction as a Core Function of Intelligence**: A central theme is that prediction is fundamental to intelligence. Hawkins discusses how our brains continuously make predictions about sensory inputs, which aids in navigating and understanding the world. This insight is vital for developing AI systems that can mimic human-like intelligence.

- **Existential Risks and Self-Replication**: Hawkins addresses concerns about AI and existential risks, arguing that the real danger lies in self-replicating systems rather than intelligent machines themselves. He emphasizes the need for regulation and understanding of these technologies to mitigate potential risks.

## Any Notable Quotes

- "The brain is the core element in all theories of intelligence."
  - This quote underscores Hawkins' belief in the brain's fundamental role in understanding intelligence, setting the stage for his arguments about the neocortex.

- "We think of the brain as learning this model of the world, but what we learned is that there are tens of thousands of independent modeling systems going on."
  - This encapsulates the essence of the Thousand Brains Theory, highlighting the complexity and distributed nature of intelligence.

- "To make a prediction, the cortex needs to know where the finger is relative to the coffee cup."
  - This illustrates the importance of spatial awareness and reference frames in cognitive processes, linking physical interaction with mental modeling.

- "If we think about knowledge, what we know, we clearly have the only brains that have certain types of knowledge."
  - This statement reflects on the uniqueness of human intelligence and our capacity for abstract thought, distinguishing us from other species.

- "Intelligent machines will be like that too, but not limited like us."
  - This quote emphasizes the potential for intelligent machines to transcend human limitations, suggesting a future where AI can operate independently and intelligently.

## Relevant Topics or Themes

- **Distributed Intelligence**: The episode explores the idea that intelligence is not centralized but distributed across multiple systems in the brain. Hawkins argues that this understanding can reshape how we approach AI and cognitive science.

- **Neuroscience and AI**: Hawkins draws parallels between the functioning of the human brain and artificial intelligence systems, suggesting that insights from neuroscience can inform the development of more sophisticated AI.

- **Hierarchical Knowledge Representation**: The discussion delves into how the brain organizes knowledge hierarchically, from simple objects to complex concepts, emphasizing the sophistication of cognitive modeling.

- **Existential Risks of AI**: Hawkins addresses concerns about the potential dangers of AI, particularly regarding self-replicating systems, advocating for careful regulation and understanding of these technologies.

- **Philosophical Implications of Intelligence**: The conversation raises questions about the nature of consciousness and intelligence, prompting listeners to consider what it means to be intelligent and how that relates to our understanding of existence.

- **Human Nature and Existential Risks**: Hawkins expresses disappointment in human nature, particularly regarding our evolutionary heritage and the potential for destructive behaviors. He emphasizes the importance of understanding our cognitive processes to mitigate these risks.

- **Legacy and Future Generations**: Hawkins reflects on the importance of creating a better future through understanding intelligence and the brain, hoping that his work will contribute to a more positive trajectory for humanity.

Overall, the episode presents a rich tapestry of ideas that connect neuroscience, artificial intelligence, and evolutionary biology, offering a comprehensive view of Hawkins' theories on intelligence. The discussion is characterized by Hawkins' deep understanding of the brain's mechanisms and his forward-thinking approach to the implications of AI in society.