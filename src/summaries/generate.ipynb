{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9d5c11-8454-4a4d-8d02-887b6b2b226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788dc522-0c1d-40b2-b411-d258e6c04694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain-community in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain-core in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (0.2.38)\n",
      "Requirement already satisfied: langchain-openai in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (0.1.23)\n",
      "Requirement already satisfied: openai in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (1.44.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (0.1.116)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (2.9.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.23.2)\n",
      "Requirement already satisfied: tzdata in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jamie.wen/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community langchain-core langchain-openai  openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d1b0a7-a1d4-4be1-92bd-f95bd1ebd696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                 0.2.16\n",
      "langchain-community       0.2.16\n",
      "langchain-core            0.2.38\n",
      "langchain-openai          0.1.23\n",
      "langchain-text-splitters  0.2.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9faefbb-3e55-452f-8a96-d83430e685c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_string_to_file(content, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd241b1e-43fb-47c8-b166-1edd4efa80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from langchain.chains import RefineDocumentsChain, MapReduceDocumentsChain, LLMChain, ReduceDocumentsChain, StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb01bbe-d3f9-43a3-93a3-9bcb1fce0e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o')\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50000, chunk_overlap=200)\n",
    "\n",
    "# Split your text into chunks\n",
    "with open('../raw/transcripts-podcast/andrew_callaghan_transcript.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8836b9-8a7b-435d-9c89-288623a384ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User command\n",
    "user_command=\"\"\"\n",
    "Analysis the podcast episode from the Lex Fridman Podcast series. Summarise the key points discussed in the episode with a focus on: \n",
    "1) The main arguments presented \n",
    "2) Any notable quotes from the guest \n",
    "3) Relevant topics or themes covered\n",
    "Ensure the summary is clear and concise, only response the above 3 sections.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735075e-9f27-4b67-a041-3ca9a1342759",
   "metadata": {},
   "source": [
    "## RefineDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5a6d2a-df95-45a3-b80c-dd9dd3b2b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/g14l2wls2tb0fyw1k42qsspr0000gq/T/ipykernel_77335/4186316529.py:13: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  initial_chain = LLMChain(llm=llm, prompt=initial_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Define prompts\n",
    "document_prompt = PromptTemplate(input_variables=[\"page_content\"], template=\"{page_content}\")\n",
    "initial_prompt = PromptTemplate.from_template(user_command + \": {context}\")\n",
    "initial_chain = LLMChain(llm=llm, prompt=initial_prompt)\n",
    "\n",
    "refine_prompt = PromptTemplate.from_template(\n",
    "    \"Here's a summary so far: {prev_response}\\n\"\n",
    "    \"Now refine it with this additional context: {context}\\n\"\n",
    "    user_command\n",
    ")\n",
    "refine_chain = LLMChain(llm=llm, prompt=refine_prompt)\n",
    "\n",
    "# Create the RefineDocumentsChain\n",
    "chain = RefineDocumentsChain(\n",
    "    initial_llm_chain=initial_chain,\n",
    "    refine_llm_chain=refine_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=\"context\",\n",
    "    initial_response_name=\"prev_response\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Generate the summary\n",
    "summary_refine = chain.invoke(docs)\n",
    "print(len(summary_refine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5623c609-bf75-4348-9a8d-fe0eebe28a3e",
   "metadata": {},
   "source": [
    "## MapReduceDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bac0d4e-2423-4ef0-ae02-3da007aba309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "map_prompt = PromptTemplate.from_template(user_command + \"{context}\")\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "reduce_prompt = PromptTemplate.from_template(user_command + \"{context}\")\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain,\n",
    "    document_variable_name=\"context\"\n",
    ")\n",
    "\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    token_max=4000\n",
    ")\n",
    "\n",
    "chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    document_variable_name=\"context\"\n",
    ")\n",
    "\n",
    "# Generate the summary\n",
    "summary_mapreduce = chain.invoke(docs)\n",
    "print(len(summary_mapreduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "843e5378-c20f-4415-8239-1c699c48f2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Key Points Discussed\n",
       "\n",
       "1. **Main Arguments Presented:**\n",
       "   - **Journalism as a Therapeutic Mechanism:** Andrew Callaghan discusses how journalism has been a therapeutic outlet for him, especially in dealing with his Hallucinogen Persisting Perception Disorder (HPPD) and depersonalization.\n",
       "   - **Exploration of Extremes:** Callaghan emphasizes his interest in exploring the fringes of society, from QAnon adherents to residents of O-Block, and how these experiences validate his sense of reality.\n",
       "   - **Critique of Traditional Education:** Both Callaghan and Fridman critique the traditional education system, highlighting its rigidity and lack of engagement for students with specific interests.\n",
       "   - **Substance Use and Creativity:** The conversation touches on the role of substances like alcohol and drugs in creative processes, with Callaghan reflecting on his past substance use and its impact on his work.\n",
       "\n",
       "2. **Notable Quotes from the Guest:**\n",
       "   - \"Being a journalist gives you a ticket to everywhere that you want to go in life. It allows you to step into different realities almost and then go back to yours and it just keeps life interesting.\"\n",
       "   - \"I think fame getting to your head. If you spend more than a hundred bucks on sunglasses, you've officially gone off the deep end.\"\n",
       "   - \"The open road never goes anywhere, and it's kind of like, I see an invisible door in the corner of the room all the time. That makes me more comfortable because I'm like, 'Hey, at the end of the day, if I'm bummed out, I can go hit the road and I'm sure there's going to be a fun time ahead.'\"\n",
       "\n",
       "3. **Relevant Topics or Themes Covered:**\n",
       "   - **HPPD and Mental Health:** Callaghan's experience with HPPD and its psychological effects, including depersonalization and derealization.\n",
       "   - **Gonzo Journalism:** The influence of gonzo journalism and figures like Hunter S. Thompson on Callaghan's work.\n",
       "   - **Substance Use:** The discussion on the role of alcohol and drugs in creative processes and personal life.\n",
       "   - **Education System:** Critique of the traditional education system and the need for more engaging and interest-based learning.\n",
       "   - **Hitchhiking and Vagabonding:** Callaghan's hitchhiking journey across the United States and the insights gained from that experience.\n",
       "   - **Existential Reflections:** Reflections on the insignificance of human existence in the grand scheme of the universe, touching on topics like space and black holes.\n",
       "\n",
       "The episode provides a deep dive into Andrew Callaghan's unique perspective on journalism, mental health, and the human experience, enriched by his personal anecdotes and philosophical reflections."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_markdown\n",
    "display_markdown(summary_mapreduce['output_text'], raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cc5d945-c75c-4daf-86f6-1a9fba934aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string_to_file(summary_mapreduce['output_text'], \"gpt4o-mapreduce.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2c15de3-be95-48ff-af72-376bfbde8063",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for MapReduceDocumentsChain\n__root__\n  llm_chain must be provided (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MapReduceDocumentsChain\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the MapReduce chain with example parameters\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m map_reduce_chain \u001b[38;5;241m=\u001b[39m \u001b[43mMapReduceDocumentsChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreducer_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Invoke the chain to process the documents\u001b[39;00m\n\u001b[1;32m      7\u001b[0m summary_mapreduce \u001b[38;5;241m=\u001b[39m map_reduce_chain\u001b[38;5;241m.\u001b[39minvoke(docs)\n",
      "File \u001b[0;32m~/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:113\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/lexnotes/src/venv/lib/python3.12/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for MapReduceDocumentsChain\n__root__\n  llm_chain must be provided (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "# Initialize the MapReduce chain with example parameters\n",
    "map_reduce_chain = MapReduceDocumentsChain(max_docs=100, reducer_config={'method': 'avg'})\n",
    "\n",
    "# Invoke the chain to process the documents\n",
    "summary_mapreduce = map_reduce_chain.invoke(docs)\n",
    "print(summary_mapreduce['output_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
