{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f9d5c11-8454-4a4d-8d02-887b6b2b226f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:06:40.114102Z",
     "iopub.status.busy": "2024-09-11T08:06:40.110217Z",
     "iopub.status.idle": "2024-09-11T08:06:41.452165Z",
     "shell.execute_reply": "2024-09-11T08:06:41.451237Z",
     "shell.execute_reply.started": "2024-09-11T08:06:40.113523Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "%pip install python-dotenv pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "788dc522-0c1d-40b2-b411-d258e6c04694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:06:41.454104Z",
     "iopub.status.busy": "2024-09-11T08:06:41.453881Z",
     "iopub.status.idle": "2024-09-11T08:06:42.695660Z",
     "shell.execute_reply": "2024-09-11T08:06:42.695153Z",
     "shell.execute_reply.started": "2024-09-11T08:06:41.454081Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain langchain-community langchain-core langchain-openai  openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19d1b0a7-a1d4-4be1-92bd-f95bd1ebd696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:06:42.696952Z",
     "iopub.status.busy": "2024-09-11T08:06:42.696779Z",
     "iopub.status.idle": "2024-09-11T08:06:43.362560Z",
     "shell.execute_reply": "2024-09-11T08:06:43.360990Z",
     "shell.execute_reply.started": "2024-09-11T08:06:42.696934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                 0.2.16\n",
      "langchain-community       0.2.16\n",
      "langchain-core            0.2.38\n",
      "langchain-openai          0.1.23\n",
      "langchain-text-splitters  0.2.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "533afebb-02be-4d87-9747-91e552f6f1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:06:44.857037Z",
     "iopub.status.busy": "2024-09-11T08:06:44.856622Z",
     "iopub.status.idle": "2024-09-11T08:06:46.370505Z",
     "shell.execute_reply": "2024-09-11T08:06:46.369773Z",
     "shell.execute_reply.started": "2024-09-11T08:06:44.857009Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install jupyterlab_execute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9faefbb-3e55-452f-8a96-d83430e685c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:06:47.859010Z",
     "iopub.status.busy": "2024-09-11T08:06:47.858622Z",
     "iopub.status.idle": "2024-09-11T08:06:47.863871Z",
     "shell.execute_reply": "2024-09-11T08:06:47.863204Z",
     "shell.execute_reply.started": "2024-09-11T08:06:47.858980Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_string_to_file(content, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd241b1e-43fb-47c8-b166-1edd4efa80b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:06:50.333160Z",
     "iopub.status.busy": "2024-09-11T08:06:50.332306Z",
     "iopub.status.idle": "2024-09-11T08:06:50.347583Z",
     "shell.execute_reply": "2024-09-11T08:06:50.346989Z",
     "shell.execute_reply.started": "2024-09-11T08:06:50.333128Z"
    }
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from langchain.chains import RefineDocumentsChain, MapReduceDocumentsChain, LLMChain, ReduceDocumentsChain, StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "from langchain.schema import StrOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e40a7f1-e4c2-44a5-abe7-45d03b713764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:06:55.566596Z",
     "iopub.status.busy": "2024-09-11T08:06:55.566241Z",
     "iopub.status.idle": "2024-09-11T08:06:55.571265Z",
     "shell.execute_reply": "2024-09-11T08:06:55.570375Z",
     "shell.execute_reply.started": "2024-09-11T08:06:55.566571Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_file(filepath):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=50000, chunk_overlap=200)\n",
    "    with open(filepath, 'r') as file:\n",
    "        text = file.read()\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    print(f'{filepath} docs:{len(docs)}')\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf8836b9-8a7b-435d-9c89-288623a384ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:11:00.396503Z",
     "iopub.status.busy": "2024-09-11T08:11:00.395027Z",
     "iopub.status.idle": "2024-09-11T08:11:00.404497Z",
     "shell.execute_reply": "2024-09-11T08:11:00.403416Z",
     "shell.execute_reply.started": "2024-09-11T08:11:00.396434Z"
    }
   },
   "outputs": [],
   "source": [
    "user_command=\"\"\"\n",
    "Provide a detailed analysis of the Lex Fridman Podcast episode. \n",
    "Your summary should be comprehensive yet well-structured, covering the breadth and depth of the discussion. \n",
    "Organize your response under the following headings:\n",
    "\n",
    "## The main arguments \n",
    "\n",
    "---\n",
    "instruction for this section\n",
    "- List at least 5 key arguments or points made during the episode\n",
    "- provide a brief explanation and its significance in the context of the discussion\n",
    "- Highlight any counterarguments or alternative perspectives mentioned\n",
    "---\n",
    "\n",
    "## Any notable quotes \n",
    "\n",
    "---\n",
    "instruction for this section\n",
    "- Include at least 5 direct quotes that encapsulate important ideas or memorable moments\n",
    "- provide a sentence of context explaining its relevance or impact\n",
    "---\n",
    "\n",
    "## Relevant topics or themes\n",
    "\n",
    "---\n",
    "instruction for this section\n",
    "- Identify and explain at least 5 major themes or topics discussed in the episode\n",
    "- provide examples of how it was explored in the conversation\n",
    "- Note any connections between different themes or how they relate to broader societal issues\n",
    "---\n",
    "\n",
    "Additional Guidelines:\n",
    "\n",
    "Use clear and concise bullet points under each heading\n",
    "Provide brief explanations for any specialized terms, events, or concepts mentioned\n",
    "Highlight any unique aspects of the episode, such as the interviewing style or guest's background\n",
    "Include a mix of factual information, personal anecdotes shared by the guest, and any hypothetical scenarios discussed\n",
    "If applicable, note any evolution in the guest's perspectives throughout the conversation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9eee9492-56fb-4f21-a72e-e0dd56efb035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:11:02.301620Z",
     "iopub.status.busy": "2024-09-11T08:11:02.301096Z",
     "iopub.status.idle": "2024-09-11T08:11:02.341342Z",
     "shell.execute_reply": "2024-09-11T08:11:02.340933Z",
     "shell.execute_reply.started": "2024-09-11T08:11:02.301594Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "def summerise(docs):\n",
    "    document_prompt = PromptTemplate(input_variables=[\"page_content\"], template=\"{page_content}\")\n",
    "    initial_prompt = PromptTemplate.from_template(user_command + \": {context}\")\n",
    "    initial_chain = LLMChain(llm=llm, prompt=initial_prompt)\n",
    "    \n",
    "    refine_prompt = PromptTemplate.from_template(\n",
    "        \"Here's a summary so far: {prev_response}\\n\" +\n",
    "        \"Now refine it with this additional context: {context}\\n\" +\n",
    "        user_command\n",
    "    )\n",
    "    refine_chain = LLMChain(llm=llm, prompt=refine_prompt)\n",
    "    \n",
    "    chain = RefineDocumentsChain(\n",
    "        initial_llm_chain=initial_chain,\n",
    "        refine_llm_chain=refine_chain,\n",
    "        document_prompt=document_prompt,\n",
    "        document_variable_name=\"context\",\n",
    "        initial_response_name=\"prev_response\",\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary_refine = chain.invoke(docs)\n",
    "    \n",
    "    print(f'summary: {len(summary_refine['output_text'])}')\n",
    "    return summary_refine['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7abab-b900-4a9e-ba94-270161bbf338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T08:59:49.411733Z",
     "iopub.status.busy": "2024-09-10T08:59:49.410659Z",
     "iopub.status.idle": "2024-09-10T08:59:49.418534Z",
     "shell.execute_reply": "2024-09-10T08:59:49.417191Z",
     "shell.execute_reply.started": "2024-09-10T08:59:49.411680Z"
    }
   },
   "source": [
    "## Summerise in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f48131d-954d-479e-96c8-a470c391c561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T08:11:05.838923Z",
     "iopub.status.busy": "2024-09-11T08:11:05.838543Z",
     "iopub.status.idle": "2024-09-11T08:16:27.707848Z",
     "shell.execute_reply": "2024-09-11T08:16:27.706218Z",
     "shell.execute_reply.started": "2024-09-11T08:11:05.838899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walter_isaacson_transcript.txt\n",
      "../1-raw/transcripts-podcast/walter_isaacson_transcript.txt docs:3\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "summary: 6336\n",
      "bassem_youssef_transcript.txt\n",
      "../1-raw/transcripts-podcast/bassem_youssef_transcript.txt docs:4\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "summary: 7061\n",
      "jared_kushner_transcript.txt\n",
      "../1-raw/transcripts-podcast/jared_kushner_transcript.txt docs:6\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "summary: 6831\n",
      "george_hotz_3_transcript.txt\n",
      "../1-raw/transcripts-podcast/george_hotz_3_transcript.txt docs:6\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "summary: 6210\n",
      "james_sexton_transcript.txt\n",
      "../1-raw/transcripts-podcast/james_sexton_transcript.txt docs:5\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "summary: 6090\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"../1-raw/transcripts-podcast/\"\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path)[:5]:\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    print(filename)\n",
    "\n",
    "    # invoke the summary\n",
    "    docs=split_file(file_path)\n",
    "    summary=summerise(docs)\n",
    "\n",
    "    # save to file\n",
    "    summary_filename=filename.replace('.txt','_summary.md')\n",
    "    save_string_to_file(summary, f\"./transcript-summary/{summary_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9a949-9eb1-4c3d-baae-5e15f41994a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ec2ada8f-db3c-4b58-9d94-02d3ede3cfae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
